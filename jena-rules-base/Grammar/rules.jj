/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Rules Grammar.

options
{
  // \ u processed after parsing in strings and IRIs, nowhere else.
  JAVA_UNICODE_ESCAPE   = false ;
  UNICODE_INPUT         = true ;

  STATIC                = false ;
//   DEBUG_PARSER          = true ;
//   DEBUG_TOKEN_MANAGER   = true ;
}

PARSER_BEGIN(RulesJavacc)
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.seaborne.jena.rules.lang.parser.javacc;

import org.apache.jena.graph.*;
import org.seaborne.jena.rules.lang.parser.RulesParserBase;
import org.apache.jena.sparql.core.Var ;
import org.seaborne.jena.rules.*;
import org.seaborne.jena.rules.store.*;
import static org.apache.jena.riot.lang.extra.LangParserLib.*;

public class RulesJavacc extends RulesParserBase
{}
PARSER_END(RulesJavacc)

// Entry points

// A whole ruleset
RuleSet parseRuleSet(): { RuleSet ruleSet; }
{
    ByteOrderMark()
    (Directive())*
    ruleSet = RuleSet()
    <EOF>
    { return ruleSet; }
}

Rel parseAtom() : { Rel rel; }
{
    ByteOrderMark()
    (Directive())*
    rel = Atom()
    (<DOT>)?
    <EOF>
    { return rel; }
}

Rule parseRule() : { Rule rule; }
{
    ByteOrderMark()
    (Directive())*
    rule = Rule()
    (<DOT>)?
    <EOF>
    { return rule; }
}

RelStore parseData() : { Rel atom; RelStoreBuilder builder = RelStoreSimple.create(); }
{
    ByteOrderMark()
    (Directive())*
    ( atom = Atom() (<DOT>)? {builder.add(atom);} )* 
    <EOF>
    { return builder.build(); }
}

// ----

void ByteOrderMark() : {}
{
  (<BOM>)?
}

// Turtle [3] directive
// Rules: SPARQL style only.
// Rules: Must be first.

void Directive() : { Token t ; String iri ; }
{
    <PREFIX> t = <PNAME_NS> iri = IRIREF()
    { String s = fixupPrefix(t.image, t.beginLine, t.beginColumn) ;
      setPrefix(s, iri, t.beginLine, t.beginColumn) ; }
 |
    t = <BASE> iri = IRIREF()
    { setBase(iri, t.beginLine, t.beginColumn) ; }
}

RuleSet RuleSet() : { Rule rule; RuleSet ruleSet; }
{
    { startRuleSet(); }
    ( rule = Rule() <DOT> { accumulateRule(rule); } )*
    { ruleSet = finishRuleSet();
      return ruleSet;
    }
}

Rule Rule() : { Rel a;}
{
   { startRule(); }
   a = Atom()
   { ruleHead(a); }
   // Facts are syntactically rules without a body.
   (
      ( <RDEF> | <BCK_ARROW> )
      ( a = Atom() { ruleBodyAtom(a); }
        ((<COMMA>)?  a = Atom() { ruleBodyAtom(a); })*
      )?
   )?
   { Rule rule = finishRule();
     return rule;
   }
}

Rel Atom() : { Token t ; String name = "" ; Node termOrVar ; }
{
   // Caveat <PREFIX> and <BASE>!
   (t = <NAME> { name = t.image; })?
   <LPAREN>
   { startAtom(name); }
   ( termOrVar = TermOrVar() { atomTerm(termOrVar) ; }
     ( (<COMMA>)?
       termOrVar = TermOrVar() { atomTerm(termOrVar) ; }
     )*
   )?
   <RPAREN>
   {
     Rel atom = finishAtom();
     return atom;
   }
}

Node TermOrVar() : { Node n ; }
{
   (n = Term() | n = Var() )
   { return n ; }
}

Node Term(): { Node term ; String iri; }
{
   ( iri = iri() { term = createNode(iri, token.beginLine, token.beginColumn) ; }
//  | term = BlankNode()
  | term = Literal()
  | term = TripleStar()
  | <UNDERSCORE> { term = Node.ANY; }
  )
  { return term ; } 
}

Var Var() : { Token t ;}
{
    ( t = <VAR1> | t = <VAR2> )
    { return createVariable(t.image, t.beginLine, t.beginColumn) ; }
}

Node TripleStar() : { Node s , p , o ; Token t ; }
{
  t = <LT2>
    { int beginLine = t.beginLine; int beginColumn = t.beginColumn; t = null; }
//  s = Subject()
//  p = Predicate()
//  o = ObjectX()
  s = TermOrVar()
  p = TermOrVar()
  o = TermOrVar()
  <GT2>
  { checkTripleTerm(s, p, o, beginLine, beginColumn);
    Node n = createTripleTerm(s, p, o, beginLine, beginColumn);
    return n;
  }
}

// Turtle [13] literal
Node Literal() : { Node n ;}
{
  n = RDFLiteral()      { return n ; }
| n = NumericLiteral()  { return n ; }
| n = BooleanLiteral()  { return n ; }
}

// Turtle [16] NumericLiteral
Node NumericLiteral() : { Token t ; }
{
  (
    t = <INTEGER> { return createLiteralInteger(t.image, t.beginLine, t.beginColumn) ; }
  | t = <DECIMAL> { return createLiteralDecimal(t.image, t.beginLine, t.beginColumn) ; }
  | t = <DOUBLE>  { return createLiteralDouble(t.image, t.beginLine, t.beginColumn) ; }
  )
}

// Turtle [128s] RDFLiteral
Node RDFLiteral() : { Token t ; String lex = null ; }
{
  lex = String()
  // Optional lang tag and datatype.
  { String lang = null ; String uri = null ; }
  (
    lang = LangTag()
  |
    <DATATYPE> uri = iri()
  )?
    { return createLiteral(lex, lang, uri, token.beginLine, token.beginColumn) ; }
} 

String LangTag() : { Token t ; }
{
  // Enumerate the directives here because they look like language tags.
  ( t = <LANGTAG> | t = AnyDirective() )
  { String lang = stripChars(t.image, 1) ; return lang ; }
}

Token AnyDirective() : { Token t ; }
{
    ( t = <PREFIX> | t = <BASE> ) { return t ; }
}

// Turtle [133s] BooleanLiteral
Node BooleanLiteral() : {}
{
  <TRUE> { return XSD_TRUE ; }
 |
  <FALSE> { return XSD_FALSE ; }
}

// Turtle [17] String
String String() : { Token t ; String lex ; }
{
  ( t = <STRING_LITERAL1> { lex = stripQuotes(t.image) ; }
  | t = <STRING_LITERAL2> { lex = stripQuotes(t.image) ; }
  | t = <STRING_LITERAL_LONG1> { lex = stripQuotes3(t.image) ; }
  | t = <STRING_LITERAL_LONG2> { lex = stripQuotes3(t.image) ; }
  )
    {
      checkString(lex, t.beginLine, t.beginColumn) ;
      lex = unescapeStr(lex,  t.beginLine, t.beginColumn) ;
      return lex ;
    }
}

// Turtle [135s] iri
String iri() : { String iri ; }
{
  iri = IRIREF() { return iri ; }
|
  iri = PrefixedName() { return iri ; }
}

// Turtle [136s] PrefixedName
String PrefixedName() : { Token t ; }
{
  ( t = <PNAME_LN>
    { return resolvePName(t.image, t.beginLine, t.beginColumn) ; }
  |
    t = <PNAME_NS>
    { return resolvePName(t.image, t.beginLine, t.beginColumn) ; }
  )
}

// Turtle [137s] BlankNode
Node BlankNode() :  { Token t = null ; }
{
  t = <BLANK_NODE_LABEL>
    { return createBNode(t.image, t.beginLine, t.beginColumn) ; }  
|
  t = <ANON> { return createBNode(t.beginLine, t.beginColumn) ; }

}

String IRIREF() : { Token t ; }
{
  t = <IRIref>
  { return resolveQuotedIRI(t.image, t.beginLine, t.beginColumn) ; }
}

// ------------------------------------------
// Tokens

SKIP : { " " | "\t" | "\n" | "\r" | "\f" }

TOKEN: { <#WS: " " | "\t" | "\n" | "\r" | "\f"> }

SPECIAL_TOKEN :
{ <SINGLE_LINE_COMMENT: "#" (~["\n","\r"])* ("\n"|"\r"|"\r\n")? > }

TOKEN : // Case sensitive tokens.
{
  <KW_A:  "a" >
}

TOKEN [IGNORE_CASE] :
{
   < BASE:        "base" >
|  < PREFIX:      "prefix" >

|  < TRUE:        "true" >
|  < FALSE:       "false" >
}

TOKEN :
{
  <#WSC:     <WS> | <SINGLE_LINE_COMMENT> >
| < BOM:     "\uFEFF">

| < UNDERSCORE: "_" >

// Does not start with a digit
| <NAME :  <PN_CHARS_U>
           ( <PN_CHARS_U> | ["0"-"9"] | "\u00B7" |
           ["\u0300"-"\u036F"] | ["\u203F"-"\u2040"] )* >

|  <IRIref:  "<"
               ( ~[ ">","<", "\"", "{", "}", "^", "\\", "|", "`","\u0000"-"\u0020"]
               | <UCHAR>
               )*
             ">" >

| < PLUS:    "+" >
| < MINUS:   "-" >

| <#DIGITS:        (["0"-"9"])+>
| <INTEGER:        (<PLUS>|<MINUS>)? <DIGITS> >
| <DECIMAL:        (<PLUS>|<MINUS>)? (<DIGITS>)? "." <DIGITS> >
| <DOUBLE:         (<PLUS>|<MINUS>)?
                     ( (["0"-"9"])+ "." (["0"-"9"])* <EXPONENT>
                     | "." (["0"-"9"])+ (<EXPONENT>)
			         | (["0"-"9"])+ <EXPONENT>
                     ) >
			 
| < #EXPONENT:   ["e","E"] (["+","-"])? (["0"-"9"])+ >

| < #QUOTE_3D:   "\"\"\"" >
| < #QUOTE_3S:   "'''">

| < #ECHAR:      "\\" ( "t"|"b"|"n"|"r"|"f"|"\\"|"\""|"'") >
| < #UCHAR:      <UCHAR4> | <UCHAR8> >
| < #UCHAR4:     "\\" "u" <HEX> <HEX> <HEX> <HEX> >
| < #UCHAR8:     "\\" "U" <HEX> <HEX> <HEX> <HEX> <HEX> <HEX> <HEX> <HEX> >

| < STRING_LITERAL1: 
      // Single quoted string
      "'" ( (~["'","\\","\n","\r"]) | <ECHAR> | <UCHAR> )* "'" > 
| < STRING_LITERAL2:
    // Double quoted string
      "\"" ( (~["\"","\\","\n","\r"]) | <ECHAR> | <UCHAR> )* "\"" >
| < STRING_LITERAL_LONG1:
     <QUOTE_3S> 
      ( ("'" | "''")? (~["'","\\"] | <ECHAR> | <UCHAR> ))*
     <QUOTE_3S> >

| < STRING_LITERAL_LONG2: 
     <QUOTE_3D> 
      ( ("\"" | "\"\"")? (~["\"","\\"] | <ECHAR> | <UCHAR> ))*
     <QUOTE_3D> >

| < LPAREN:    "(" >
| < RPAREN:    ")" >

| < LBRACE:    "{" >
| < RBRACE:    "}" >

| < LBRACKET:  "[" >
| < RBRACKET:  "]" >

| < ANON:      <LBRACKET> (<WSC>)* <RBRACKET> >

| < SEMICOLON: ";" >
//| < COLON: ":" >
| < COMMA:     "," >
| < DOT:       "." >

| < LT2:       "<<" >
| < GT2:       ">>" >
| < L_ANN:     "{|" >
| < R_ANN:     "|}" >

| < RDEF:           ":-" >
| < BCK_ARROW:      "<-" >
| < FWD_ARROW:      "->" >

| < DATATYPE: "^^">
| < AT: "@">

|  <PNAME_NS: (<PN_PREFIX>)? ":" >
|  <PNAME_LN: <PNAME_NS> <PN_LOCAL> >
|  <BLANK_NODE_LABEL: "_:" (<PN_CHARS_U> | ["0"-"9"]) ((<PN_CHARS>|".")* <PN_CHARS>)?  >
|  <LANGTAG: <AT> (<A2Z>)+("-" (<A2ZN>)+)* >
|  <#A2Z: ["a"-"z","A"-"Z"]>
|  <#A2ZN: ["a"-"z","A"-"Z","0"-"9"]>

| <#SURROGATE_PAIR: ["\uD800"-"\uDBFF"] ["\uDC00"-"\uDFFF"] >

| <#PN_CHARS_BASE:
          ["A"-"Z"] | ["a"-"z"] |
          ["\u00C0"-"\u00D6"] | ["\u00D8"-"\u00F6"] | ["\u00F8"-"\u02FF"] |
          ["\u0370"-"\u037D"] | ["\u037F"-"\u1FFF"] |
          ["\u200C"-"\u200D"] | ["\u2070"-"\u218F"] | ["\u2C00"-"\u2FEF"] |
          ["\u3001"-"\uD7FF"] | ["\uF900"-"\uFFFD"]
          // | [#x10000-#xEFFFF]
          // Put in surrogate pairs because by the time javacc sees codepoints,
          // they are in UTF-16.
          | <SURROGATE_PAIR>
          >
|
  // With underscore
  <#PN_CHARS_U: <PN_CHARS_BASE> | "_" >
|
  <#PN_CHARS: (<PN_CHARS_U> | "-" | ["0"-"9"] | "\u00B7" |
              ["\u0300"-"\u036F"] | ["\u203F"-"\u2040"] ) >
|
  // No leading "_", no trailing ".", can have dot inside prefix name.
  <#PN_PREFIX: <PN_CHARS_BASE> ((<PN_CHARS>|".")* <PN_CHARS>)?  >
|
  // Local part.
  <#PN_LOCAL: (<PN_CHARS_U> | ":" | ["0"-"9"] | <PLX> ) 
              ( (<PN_CHARS> | "." |":" | <PLX> )* 
                (<PN_CHARS> | ":" | <PLX>) )?  >

|  <VAR1: "?" <VARNAME> >
|  <VAR2: "$" <VARNAME> >
|
  <#VARNAME: ( <PN_CHARS_U> | ["0"-"9"] )
             ( <PN_CHARS_U> | ["0"-"9"] | "\u00B7" |
               ["\u0300"-"\u036F"] | ["\u203F"-"\u2040"] )* >
|
  <#PN_LOCAL_ESC: "\\" 
          ( "_" | 
            "~" | "." | "-" | "!" | "$" | "&" | "'" | 
           "(" | ")" | "*" | "+" | "," | ";" | "=" | 
           "/" | "?" | "#" | "@" | "%" ) >
|
  <#PLX:  <PERCENT> | <PN_LOCAL_ESC> >
|
  < #HEX: ["0"-"9"] | ["A"-"F"] | ["a"-"f"] >
|
  < #PERCENT: "%" <HEX> <HEX> >
}

// Catch-all tokens.  Must be last.  
// Any non-whitespace.  Causes a parser exception, rather than a
// token manager error (which hides the line numbers).
TOKEN:
{
  <#UNKNOWN: (~[" ","\t","\n","\r","\f" ])+ >
}

/*
# Local Variables:
# tab-width: 4
# indent-tabs-mode: nil
# comment-default-style: "//"
# End:
*/
